[{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"Apache License","title":"Apache License","text":"Version 2.0, January 2004 <http://www.apache.org/licenses/>","code":""},{"path":[]},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"id_1-definitions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"1. Definitions","title":"Apache License","text":"“License” shall mean terms conditions use, reproduction, distribution defined Sections 1 9 document. “Licensor” shall mean copyright owner entity authorized copyright owner granting License. “Legal Entity” shall mean union acting entity entities control, controlled , common control entity. purposes definition, “control” means () power, direct indirect, cause direction management entity, whether contract otherwise, (ii) ownership fifty percent (50%) outstanding shares, (iii) beneficial ownership entity. “” (“”) shall mean individual Legal Entity exercising permissions granted License. “Source” form shall mean preferred form making modifications, including limited software source code, documentation source, configuration files. “Object” form shall mean form resulting mechanical transformation translation Source form, including limited compiled object code, generated documentation, conversions media types. “Work” shall mean work authorship, whether Source Object form, made available License, indicated copyright notice included attached work (example provided Appendix ). “Derivative Works” shall mean work, whether Source Object form, based (derived ) Work editorial revisions, annotations, elaborations, modifications represent, whole, original work authorship. purposes License, Derivative Works shall include works remain separable , merely link (bind name) interfaces , Work Derivative Works thereof. “Contribution” shall mean work authorship, including original version Work modifications additions Work Derivative Works thereof, intentionally submitted Licensor inclusion Work copyright owner individual Legal Entity authorized submit behalf copyright owner. purposes definition, “submitted” means form electronic, verbal, written communication sent Licensor representatives, including limited communication electronic mailing lists, source code control systems, issue tracking systems managed , behalf , Licensor purpose discussing improving Work, excluding communication conspicuously marked otherwise designated writing copyright owner “Contribution.” “Contributor” shall mean Licensor individual Legal Entity behalf Contribution received Licensor subsequently incorporated within Work.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"id_2-grant-of-copyright-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"2. Grant of Copyright License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable copyright license reproduce, prepare Derivative Works , publicly display, publicly perform, sublicense, distribute Work Derivative Works Source Object form.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"id_3-grant-of-patent-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"3. Grant of Patent License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable (except stated section) patent license make, made, use, offer sell, sell, import, otherwise transfer Work, license applies patent claims licensable Contributor necessarily infringed Contribution(s) alone combination Contribution(s) Work Contribution(s) submitted. institute patent litigation entity (including cross-claim counterclaim lawsuit) alleging Work Contribution incorporated within Work constitutes direct contributory patent infringement, patent licenses granted License Work shall terminate date litigation filed.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"id_4-redistribution","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"4. Redistribution","title":"Apache License","text":"may reproduce distribute copies Work Derivative Works thereof medium, without modifications, Source Object form, provided meet following conditions: () must give recipients Work Derivative Works copy License; (b) must cause modified files carry prominent notices stating changed files; (c) must retain, Source form Derivative Works distribute, copyright, patent, trademark, attribution notices Source form Work, excluding notices pertain part Derivative Works; (d) Work includes “NOTICE” text file part distribution, Derivative Works distribute must include readable copy attribution notices contained within NOTICE file, excluding notices pertain part Derivative Works, least one following places: within NOTICE text file distributed part Derivative Works; within Source form documentation, provided along Derivative Works; , within display generated Derivative Works, wherever third-party notices normally appear. contents NOTICE file informational purposes modify License. may add attribution notices within Derivative Works distribute, alongside addendum NOTICE text Work, provided additional attribution notices construed modifying License. may add copyright statement modifications may provide additional different license terms conditions use, reproduction, distribution modifications, Derivative Works whole, provided use, reproduction, distribution Work otherwise complies conditions stated License.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"id_5-submission-of-contributions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"5. Submission of Contributions","title":"Apache License","text":"Unless explicitly state otherwise, Contribution intentionally submitted inclusion Work Licensor shall terms conditions License, without additional terms conditions. Notwithstanding , nothing herein shall supersede modify terms separate license agreement may executed Licensor regarding Contributions.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"id_6-trademarks","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"6. Trademarks","title":"Apache License","text":"License grant permission use trade names, trademarks, service marks, product names Licensor, except required reasonable customary use describing origin Work reproducing content NOTICE file.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"id_7-disclaimer-of-warranty","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"7. Disclaimer of Warranty","title":"Apache License","text":"Unless required applicable law agreed writing, Licensor provides Work (Contributor provides Contributions) “” BASIS, WITHOUT WARRANTIES CONDITIONS KIND, either express implied, including, without limitation, warranties conditions TITLE, NON-INFRINGEMENT, MERCHANTABILITY, FITNESS PARTICULAR PURPOSE. solely responsible determining appropriateness using redistributing Work assume risks associated exercise permissions License.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"id_8-limitation-of-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"8. Limitation of Liability","title":"Apache License","text":"event legal theory, whether tort (including negligence), contract, otherwise, unless required applicable law (deliberate grossly negligent acts) agreed writing, shall Contributor liable damages, including direct, indirect, special, incidental, consequential damages character arising result License use inability use Work (including limited damages loss goodwill, work stoppage, computer failure malfunction, commercial damages losses), even Contributor advised possibility damages.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"id_9-accepting-warranty-or-additional-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"9. Accepting Warranty or Additional Liability","title":"Apache License","text":"redistributing Work Derivative Works thereof, may choose offer, charge fee , acceptance support, warranty, indemnity, liability obligations /rights consistent License. However, accepting obligations, may act behalf sole responsibility, behalf Contributor, agree indemnify, defend, hold Contributor harmless liability incurred , claims asserted , Contributor reason accepting warranty additional liability. END TERMS CONDITIONS","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/LICENSE.html","id":"appendix-how-to-apply-the-apache-license-to-your-work","dir":"","previous_headings":"","what":"APPENDIX: How to apply the Apache License to your work","title":"Apache License","text":"apply Apache License work, attach following boilerplate notice, fields enclosed brackets [] replaced identifying information. (Don’t include brackets!) text enclosed appropriate comment syntax file format. also recommend file class name description purpose included “printed page” copyright notice easier identification within third-party archives.","code":"Copyright [yyyy] [name of copyright owner]  Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."},{"path":"https://janickweberpals.github.io/encore.analytics/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Janick Weberpals. Author, maintainer.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Weberpals J (2025). encore.analytics: Functions Wrappers Streamline Complex Analytic Workflows Real-World Data Studies Based ENCORE Trial Emulation Project. R package version 0.1.0, https://janickweberpals.github.io/encore.analytics/.","code":"@Manual{,   title = {encore.analytics: Functions and Wrappers To Streamline Complex Analytic Workflows in Real-World Data Studies Based On The ENCORE Trial Emulation Project},   author = {Janick Weberpals},   year = {2025},   note = {R package version 0.1.0},   url = {https://janickweberpals.github.io/encore.analytics/}, }"},{"path":"https://janickweberpals.github.io/encore.analytics/index.html","id":"encoreanalytics-","dir":"","previous_headings":"","what":"Functions and Wrappers To Streamline Complex Analytic Workflows in Real-World Data Studies Based On The ENCORE Trial Emulation Project","title":"Functions and Wrappers To Streamline Complex Analytic Workflows in Real-World Data Studies Based On The ENCORE Trial Emulation Project","text":"goal encore.analytics …","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Functions and Wrappers To Streamline Complex Analytic Workflows in Real-World Data Studies Based On The ENCORE Trial Emulation Project","text":"can install development version encore.analytics GitHub :","code":"# install.packages(\"pak\") pak::pak(\"janickweberpals/encore.analytics\")"},{"path":"https://janickweberpals.github.io/encore.analytics/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Functions and Wrappers To Streamline Complex Analytic Workflows in Real-World Data Studies Based On The ENCORE Trial Emulation Project","text":"comprehensive walkthrough examples, please refer vignette : https://janickweberpals.github.io/imputation-ps-workflows/","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/cox_pooling.html","id":null,"dir":"Reference","previous_headings":"","what":"Manually fit and pool Cox proportional hazards model results from multiple imputed datasets — cox_pooling","title":"Manually fit and pool Cox proportional hazards model results from multiple imputed datasets — cox_pooling","text":"Function manually fits pools results Cox proportional hazards models using list imputed datasets.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/cox_pooling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manually fit and pool Cox proportional hazards model results from multiple imputed datasets — cox_pooling","text":"","code":"cox_pooling(   x,   surv_formula = stats::as.formula(survival::Surv(fu_itt_months, death_itt) ~ treat) )"},{"path":"https://janickweberpals.github.io/encore.analytics/reference/cox_pooling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manually fit and pool Cox proportional hazards model results from multiple imputed datasets — cox_pooling","text":"x list imputed datasets weights raking weights (raking_weights) cluster (matched datasets ) surv_formula formula Cox proportional hazards model (default Surv(fu_itt_months, death_itt) ~ treat)","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/cox_pooling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Manually fit and pool Cox proportional hazards model results from multiple imputed datasets — cox_pooling","text":"list data frames updated raking weights (raking_weights)","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/cox_pooling.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Manually fit and pool Cox proportional hazards model results from multiple imputed datasets — cox_pooling","text":"function requires list imputed data frames weights cluster (matching) information formula Cox proportional hazards model. data frames must column names weights subclass (matched datasets indicate cluster membership). convenience wrapper fitting Cox models multiple imputed datasets come mimids wimids object. useful intermediate steps analysis pipeline, computing raking weights via raking_weights far straightforward implement mimids wimids object. function follows following logic: Fit Cox proportional hazards model imputed dataset; subclass column present data, used cluster variable matched pairs Pool results using pool.scalar function mice package, , univariate estimates (qbar) pooled via formula (3.1.2) Rubin (1987) total variance (t) estimated via robust standardard errors according formula (3.1.5) Rubin (1987). Compute confidence intervals exponentiate results via exp(qbar +/- 1.96 * sqrt(t))","code":""},{"path":[]},{"path":"https://janickweberpals.github.io/encore.analytics/reference/cox_pooling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manually fit and pool Cox proportional hazards model results from multiple imputed datasets — cox_pooling","text":"","code":"library(encore.analytics) library(mice) #>  #> Attaching package: ‘mice’ #> The following object is masked from ‘package:stats’: #>  #>     filter #> The following objects are masked from ‘package:base’: #>  #>     cbind, rbind library(MatchThem) #>  #> Attaching package: ‘MatchThem’ #> The following objects are masked from ‘package:mice’: #>  #>     cbind, pool #> The following object is masked from ‘package:base’: #>  #>     cbind  # simulate a cohort with 1,000 patients with 20% missing data data <- simulate_data(  n = 500,  imposeNA = TRUE,  propNA = 0.2  )  # impute the data set.seed(42) mids <- mice(data, m = 5, print = FALSE) #> Warning: Number of logged events: 801  # fit a propensity score model fit <- as.formula(treat ~ dem_age_index_cont + dem_sex_cont + c_smoking_history)  # weight (or alternatively match) patients within each imputed dataset wimids <- weightthem(  formula = fit,  datasets = mids,  approach = \"within\",  method = \"glm\",  estimand = \"ATO\"  ) #> Estimating weights     | dataset: #1 #>  #2 #>  #3 #>  #4 #>  #5 #>   # create a list of imputed and weighted datasets wimids_list <- MatchThem::complete(wimids, action = \"all\", all = FALSE, include = FALSE)  # fit a survival model cox_fit <- as.formula(survival::Surv(fu_itt_months, death_itt) ~ treat)  # fit and pool Cox proportional hazards model results cox_pooling(wimids_list, surv_formula = cox_fit) #>    term  estimate  std.error statistic      p.value  conf.low conf.high #> 1 treat 0.7334003 0.08794506 -3.525651 0.0004623598 0.6170148 0.8717392 #>              b       df dfcom        fmi      lambda m         riv        ubar #> 1 4.813004e-05 486.9941   496 0.01151869 0.007467489 5 0.007523672 0.007676578"},{"path":"https://janickweberpals.github.io/encore.analytics/reference/create_table1.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper around gtsummary::tbl_summary() to create a beautiful Table 1 quickly — create_table1","title":"Wrapper around gtsummary::tbl_summary() to create a beautiful Table 1 quickly — create_table1","text":"Builds table 1 using gtsummary package. function takes one-row-per-patient dataframe creates summary table covariates stratified treatment group.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/create_table1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper around gtsummary::tbl_summary() to create a beautiful Table 1 quickly — create_table1","text":"","code":"create_table1(   x = NULL,   covariates = NULL,   covariates_labels = NULL,   treat = \"treat\",   explicit_na_categorical = TRUE )"},{"path":"https://janickweberpals.github.io/encore.analytics/reference/create_table1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper around gtsummary::tbl_summary() to create a beautiful Table 1 quickly — create_table1","text":"x dataframe individual-level patient data one-row-per-patient format treatment stratification variable covariates displayed Table 1 covariates character vector columns/covariate names displayed Table 1 covariates_labels named character vector list formulas specifying variables labels covariate-label pairs display table treat character specifying column name treatment variable explicit_na_categorical logical, missings categorical variables explicitly included separate category (default TRUE)","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/create_table1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrapper around gtsummary::tbl_summary() to create a beautiful Table 1 quickly — create_table1","text":"object class \"tbl_summary\" \"gtsummary\"","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/create_table1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wrapper around gtsummary::tbl_summary() to create a beautiful Table 1 quickly — create_table1","text":"Wrapper tbl_summary. function create_table1 wrapper around gtsummary::tbl_summary() function. designed create summary table covariates stratified treatment group. function requires one-row-per-patient dataframe creates summary table covariates stratified treatment group.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/create_table1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper around gtsummary::tbl_summary() to create a beautiful Table 1 quickly — create_table1","text":"","code":"if (FALSE) { # \\dontrun{ library(encore.analytics)  # simulate a cohort with 1,000 patients with 20% missing data data <- simulate_data(   n = 1000,   imposeNA = TRUE,   propNA = 0.2   )  # create a Table 1 create_table1(   x = data,   covariates = c(\"dem_age_index_cont\", \"dem_sex_cont\", \"c_smoking_history\"),   covariates_labels = list(     \"dem_age_index_cont\" = \"Age\",     \"dem_sex_cont\" = \"Sex\",     \"c_smoking_history\" = \"Smoking history\"     ),   treat = \"treat\"   ) } # }"},{"path":"https://janickweberpals.github.io/encore.analytics/reference/install_on_demand.html","id":null,"dir":"Reference","previous_headings":"","what":"Install package on demand — install_on_demand","title":"Install package on demand — install_on_demand","text":"function checks package installed. , asks user want install . user agrees, installs package CRAN.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/install_on_demand.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install package on demand — install_on_demand","text":"","code":"install_on_demand(pkg, quiet = FALSE, ...)"},{"path":"https://janickweberpals.github.io/encore.analytics/reference/install_on_demand.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install package on demand — install_on_demand","text":"pkg character string name package quiet logical. TRUE, suppresses messages ... additional arguments passed install.packages","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/km_pooling.html","id":null,"dir":"Reference","previous_headings":"","what":"Pooled Kaplan-Meier estimate and survival curve — km_pooling","title":"Pooled Kaplan-Meier estimate and survival curve — km_pooling","text":"Computes pooled median survival Kaplan-Meier estimates using Rubin's rule outputs corresponding Kaplan-Meier curve across imputed matched/weighted datasets","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/km_pooling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Kaplan-Meier estimate and survival curve — km_pooling","text":"","code":"km_pooling(   x = NULL,   surv_formula = stats::as.formula(survival::Surv(fu_itt_months, death_itt) ~ treat) )"},{"path":"https://janickweberpals.github.io/encore.analytics/reference/km_pooling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pooled Kaplan-Meier estimate and survival curve — km_pooling","text":"x imputed matched (mimids) weighted (wimids) object surv_formula specification survival model formula fitted","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/km_pooling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pooled Kaplan-Meier estimate and survival curve — km_pooling","text":"list pooled median survival estimate pooled Kaplan-Meier curve km_median_survival: strata = stratum t_median = median survival time t_lower = lower 95% CI median survival time t_upper = upper 95% CI median survival time km_survival_table: strata = stratum time = observed time point m = number imputed datasets qbar = pooled univariate estimate complementary log-log transformed survival probabilities, see formula (3.1.2) Rubin (1987) t = total variance pooled univariate estimate complementary log-log transformed survival probabilities, formula (3.1.5) Rubin (1987) se = total standard error pooled estimate (derived sqrt(t)) surv = back-transformed pooled survival probability lower = Wald-type lower 95% confidence interval back-transformed pooled survival probability upper = Wald-type upper 95% confidence interval back-transformed pooled survival probability km_plot: ggplot2 object Kaplan-Meier curve","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/km_pooling.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pooled Kaplan-Meier estimate and survival curve — km_pooling","text":"function requires object class mimids wimids (x), output workflow requires imputing multiple (m) datasets using mice amelia matching weighting imputed dataset via MatchThem package (see examples). function fits pre-specified survfit model (surv_formula, survfit package) compute survival probabilities individual time point according Kaplan-Meier method. matched weighted datasets, weights, cluster membership (matching ) robust variance estimates considered survfit call default. Since survival probabilities typically follow normal distributions, need transformed approximate normality first pooling across imputed datasets time points. end, survival probabilities first transformed using complementary log-log transformation (log(-log(1-pr(surv)))) recommended multiple sources (Marshall, Billingham, Bryan (2009)). pool transformed estimates across imputed datasets time points, pool.scalar function used apply Rubin's rule combine pooled estimates (qbar) according formula (3.1.2) Rubin (1987) compute corresponding total variance (t) pooled estimate according formula (3.1.5) Rubin (1987). pooled survival probabilities back-transformed via 1-exp(-exp(qbar)) pooled survival probability estimates 1-exp(-exp(qbar +/- 1.96*sqrt(t))) lower upper 95% confidence intervals. formula indicates, pooled standard error computed square root total variance. vertically stacked table transformed backtransformed estimates returned km_survival_table table. Finally, median survival time extracted km_survival_table table determining time survival probability drops .5 first time. sub-function Terry M. Therneau's print.survfit function used. Therneau also considers edge cases/nuisances (x = time, y = surv): Nuisance 1: one y's exactly .5, want mean corresponding x first x y<.5. need use equivalent .equal check .5 however: survfit(Surv(1:100)~1) gives value .5 + 1.1e-16 due roundoff error. Nuisance 2: may NA y's Nuisance 3: y's <=.5, return NA Nuisance 4: obs (many) .5 may censored, giving stretch values = .5 +- epsilon function follows following logic: Fit Kaplan-Meier survival function imputed matched/weighted dataset Transform survival probabilities using complementary log-log transformation Pool transformed survival probabilities compute total variance using Rubin's rule Back-transform pooled survival probabilities compute 95% confidence intervals Extract median survival time corresponding 95% confidence intervals Plot Kaplan-Meier curve pooled survival probabilities confidence intervals references: https://stefvanbuuren.name/fimd/sec-pooling.html https://link.springer.com/article/10.1007/s10198-008-0129-y https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-015-0048-4","code":""},{"path":[]},{"path":"https://janickweberpals.github.io/encore.analytics/reference/km_pooling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pooled Kaplan-Meier estimate and survival curve — km_pooling","text":"","code":"library(encore.analytics)  library(mice)  library(MatchThem)   # simulate a cohort with 1,000 patients with 20% missing data  data <- simulate_data(    n = 500,    imposeNA = TRUE,    propNA = 0.2    )   # impute the data  set.seed(42)  mids <- mice(data, m = 5, print = FALSE) #> Warning: Number of logged events: 801   # fit a propensity score model  fit <- as.formula(treat ~ dem_age_index_cont + dem_sex_cont + c_smoking_history)   # weight (or alternatively match) patients within each imputed dataset  wimids <- weightthem(    formula = fit,    datasets = mids,    approach = \"within\",    method = \"glm\",    estimand = \"ATO\"    ) #> Estimating weights     | dataset: #1 #>  #2 #>  #3 #>  #4 #>  #5 #>    # fit a survival model  km_fit <- as.formula(survival::Surv(fu_itt_months, death_itt) ~ treat)   # estimate and pool median survival times and Kaplan-Meier curve  km_out <- km_pooling(    x = wimids,    surv_formula = km_fit    )   # median survival time  km_out$km_median_survival #> # A tibble: 2 × 4 #>   strata  t_median t_lower t_upper #>   <fct>      <dbl>   <dbl>   <dbl> #> 1 treat=0     16.7    14.0    19.6 #> 2 treat=1     20.5    17.7    24.3   # KM curve  km_out$km_plot"},{"path":"https://janickweberpals.github.io/encore.analytics/reference/raking_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate raking weights for a mimids or wimids object — raking_weights","title":"Estimate raking weights for a mimids or wimids object — raking_weights","text":"Function estimates raking weights multiple imputed matched (mimids) weighted (wimids) datasets. match distributions certain variables imputed matched/weighted datasets distribution target population (e.g., clinical trial population).","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/raking_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate raking weights for a mimids or wimids object — raking_weights","text":"","code":"raking_weights(x, targets = NULL)"},{"path":"https://janickweberpals.github.io/encore.analytics/reference/raking_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate raking weights for a mimids or wimids object — raking_weights","text":"x imputed matched (mimids) weighted (wimids) object targets list target values raking procedure","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/raking_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate raking weights for a mimids or wimids object — raking_weights","text":"list data frames updated raking weights (raking_weights)","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/raking_weights.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate raking weights for a mimids or wimids object — raking_weights","text":"function requires object class mimids wimids (x), output workflow requires imputing multiple (m) datasets using mice amelia matching weighting imputed dataset via MatchThem package (see examples). function additionally requires list target distributions (targets) variable considered raking procedure. list contain named vectors target distributions variable names vectors match variable names imputed datasets. brief, raking procedure iteratively adjusts weights make weighted sample percentages match target population percentages selected variables.multiplying current weight case factor based ratio target population proportion weighted sample proportion given category. adjustment performed sequentially category selected variable. adjusting one variable can disrupt match previous variables, process repeated selected variables cycles. iterative process minimizes Kullback-Leibler (KL) divergence continues weighted sample proportions match target population proportions categories (\"full convergence\"), change occurs. function follows following logic: Extract ith imputed dataset mimids wimids object Create temporary case/patient ID Apply anesrake function ith imputed dataset Create temporary dataframe case ID replace initial weights updated raking weights Merge temporary dataframe ith imputed dataset Drop temporary case ID Return ith imputed dataset raking weights function returns list data frames updated raking weights. updated raking weights overwrite data frame existing weights column. column can used downstream analysis (e.g., Kaplan-Meier, Cox proportional hazards regression).","code":""},{"path":[]},{"path":"https://janickweberpals.github.io/encore.analytics/reference/raking_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate raking weights for a mimids or wimids object — raking_weights","text":"","code":"library(encore.analytics)  library(mice)  library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  library(MatchThem)  library(survival)   # simulate a cohort with 1,000 patients with 20% missing data  data <- simulate_data(    n = 500,    imposeNA = TRUE,    propNA = 0.2    ) |>    # anesrake works best with factor variables    mutate(c_smoking_history = factor(ifelse(c_smoking_history == TRUE, \"Current/former\", \"Never\")))   # impute the data (create mids object)  set.seed(42)  mids <- mice(data, m = 5, print = FALSE) #> Warning: Number of logged events: 801   # define covariates for propensity score model  covariates <- data |>   select(starts_with(\"c_\"), starts_with(\"dem_\")) |>    colnames()   # define propensity score model  fit <- as.formula(paste(\"treat ~\", paste(covariates, collapse = \" + \")))   # match patients within each imputed dataset  mimids <- matchthem(    formula = fit,    datasets = mids,    approach = 'within',    method = 'nearest'    ) #>  #> Matching Observations  | dataset: #1 #> Warning: Fewer control units than treated units; not all treated units will get #> a match. #>  #2 #> Warning: Fewer control units than treated units; not all treated units will get #> a match. #>  #3 #> Warning: Fewer control units than treated units; not all treated units will get #> a match. #>  #4 #> Warning: Fewer control units than treated units; not all treated units will get #> a match. #>  #5 #> Warning: Fewer control units than treated units; not all treated units will get #> a match. #>    smoker_target <- c(.35, .65)  names(smoker_target) <- c(\"Current/former\", \"Never\")   # summarize target distributions in a named list vector  targets <- list(smoker_target)  names(targets) <- c(\"c_smoking_history\")   # estimate raking weights  mirwds <- raking_weights(    x = mimids,    targets = targets    ) #> [1] \"Raking converged in 3 iterations\" #> [1] \"Raking converged in 3 iterations\" #> [1] \"Raking converged in 3 iterations\" #> [1] \"Raking converged in 3 iterations\" #> [1] \"Raking converged in 3 iterations\""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/simulate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulates an artifical EHR-derived analysis-ready oncology dataset — simulate_data","title":"Simulates an artifical EHR-derived analysis-ready oncology dataset — simulate_data","text":"Parameterized function quickly create EHR-derived analytic cohort analytic code development.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/simulate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulates an artifical EHR-derived analysis-ready oncology dataset — simulate_data","text":"","code":"simulate_data(   n_total = 3500,   seed = 42,   include_id = TRUE,   imposeNA = TRUE,   propNA = NULL )"},{"path":"https://janickweberpals.github.io/encore.analytics/reference/simulate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulates an artifical EHR-derived analysis-ready oncology dataset — simulate_data","text":"n_total integer, number total patients seed integer, seed reproducibility include_id logical, include generated patientid variable imposeNA logical, set covariates missing propNA numeric, proportion missingness, needs 0 1","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/simulate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulates an artifical EHR-derived analysis-ready oncology dataset — simulate_data","text":"data frame simulated analytic cohort","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/simulate_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulates an artifical EHR-derived analysis-ready oncology dataset — simulate_data","text":"function simulates cohort patients oncology data. cohort simulated using Weibull distribution time event logistic distribution treatment assignment. function also allows missingness imposed data. function parameterized allow number patients simulated, seed reproducibility, whether include patient id variable.","code":""},{"path":"https://janickweberpals.github.io/encore.analytics/reference/simulate_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulates an artifical EHR-derived analysis-ready oncology dataset — simulate_data","text":"","code":"if (FALSE) { # \\dontrun{ library(encore.analytics)  data_miss <- simulate_data(   n_total = 3500,   seed = 41,   include_id = FALSE,   imposeNA = TRUE,   propNA = .33   )  head(data_miss)  } # }"}]
